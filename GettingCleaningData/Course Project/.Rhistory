x<-c(12, 13, 23, 67, 34, 23, 0)
?append
append(x, c(34, 21, 69))
length(x)
x<-append(x, c(34, 21, 69))
makeVector(x)
cachemean(x)
x<-1:10000
vec<-makeVector(x)
vec$getmean()
mx<-mean(x)
vec$setmean(mx)
vec$getmean()
cachemean(x)
source('D:/Skitch/Code/R/R-Programming/Assignment 2/makeVector.R')
source('D:/Skitch/Code/R/R-Programming/Assignment 2/cachemean.R')
x<-1:5000
makeVector(x)
cachemean(x)
source('D:/Skitch/Code/R/R-Programming/Assignment 2/makeVector.R')
source('D:/Skitch/Code/R/R-Programming/Assignment 2/makeVector.R')
vec<-makeVecto(x)
vec<-makeVector(x)
cachemean(vec)
source('D:/Skitch/Code/R/R-Programming/Assignment 2/makeVector.R')
apply(iris[, 1:4], 2, mean)
iris
sapply(split(Sepal.Length, virginica), mean)
sapply(split(iris$Sepal.Length, virginica), mean)
library(datasets)
data(iris)
sapply(split(iris$Sepal.Length, virginica), mean)
sapply(split(iris$Sepal.Length, "virginica"), mean)
sapply(split(iris$Sepal.Length, iris$Species), mean)
apply(iris[, 1:4], 2, mean)
library(datasets)
data(mtcars)
with(mtcars, tapply(mpg, cyl, mean))
hp<-sapply(split(mtcars$hp, mtcars$cyl), mean)
hp
hp[3]-hp[1]
source('D:/temp/ch2.R', echo=TRUE)
y<-rnorm(100)
x<-rnorm(100)
plot(x,y)
plot(y,x)
x<-rnorm(100, mean=50, sd=0.1)
x<-rnorm(100, mean=50, sd=0.2)
plot(y,x)
plot(x,y)
x<-1:100
plot(x,y)
y<-rnorm(100, mean=50, sd=0.1)
plot(x,y)
x<-1:100
y<-100 + x^2
plot(x,y)
x=c(2, 4, 5)
x
y=hist(100)
y=norm(100)
hist(y)
y
y=runif(100)
hist(y)
y=gauss(100)
y=rnorm(100)
hist(y)
y=qnorm(100)
y=pbeta(100)
x<-rnorm(100,mean=50, sd=10)
hist(x)
x<-rnorm(100,mean=50, sd=1)
hist(x)
x<-rnorm(1000,mean=50, sd=1)
hist(x)
x<-rnorm(1000,mean=50, sd=.1)
hist(x)
x<-rnorm(1000,mean=50, sd=30)
hist(x)
x=runif(50)
y=rnorm(50)
plot(x,y)
hist(y)
hist(x)
hist(x)
x=rnorm(500)
hist(x)
x=gnorm(500)
x=1:100
y=dnorm(100,mean=10, sd=2)
plot(x,y)
y
y=dnorm(x,mean=10, sd=2)
plot(x,y)
y=dnorm(x,mean=45, sd=20)
plot(x,y)
y=dnorm(x,mean=45, sd=20, log=TRUE)
plot(x,y)
y=dnorm(x,mean=45, sd=13)
plot(x,y)
y=dnorm(x,mean=45, sd=1)
plot(x,y)
y=dnorm(x,mean=45, sd=0.1)
plot(x,y)
y=dnorm(x,mean=45, sd=10)
plot(x,y)
y=pnorm(x,mean=45, sd=10)
plot(x,y)
y=pnorm(x,mean=45, sd=10, lower.tail=FALSE)
plot(x,y)
y=pnorm(x,mean=45, sd=10, lower.tail=FALSE, log.p=TRUE)
plot(x,y)
y=qnorm(x,mean=45, sd=10)
plot(x,y)
y=qnorm(x,mean=45, sd=1)
y=qnorm(x,mean=0, sd=1)
library(MASS)
names(Boston)
plot(medv~lstat, Boston)
fit1=lm(medv~lstat, data=Boston)
fit1
summary(fit1)
abline(fit1, color="green")
abline(fit1, col="green")
abline(fit1, col="red")
abline(fit1,col="red")
?abline
abline(-fit1, color="green")
?rbline
plot.new()
plot(medv~lstat, Boston)
abline(fit1,col="red")
R.version.string
library(swirl)
swirl()
install_from_swirl("Getting and Cleaning Data")
swril()
swirl()
mydf<-read.csv(path2csv, stringAsFactors=FALSE)
mydf<-read.csv(file=path2csv, stringAsFactors=FALSE)
mydf<-read.csv(file=path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran<-tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran,-(X:size))
filter(cran, package == "swirl")
filter(cran, r_version ==  "3.1.1", country == "US")
?Comparison
filter(cran, r_version <=  "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_or == "linux-gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version)
)
cran2<-select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3<-select(ip_id, package, size)
cran3<-select(cran,ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size / 2^10)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size * 1000)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
install.packages(RODBC)
install.packages("RODBC")
library(RODBC)
ch<-odbcConnect("RLocal")
ch
site<-as.matrix(sqlFetch(ch,)"[Enrollment].[SiteInformation]", rownames="SiteCode")
site<-as.matrix(sqlFetch(ch,"[Enrollment].[SiteInformation]", rownames="SiteCode"))
site<-as.matrix(sqlFetch(ch, "[Enrollment].[SiteInformation]", rownames="SiteCode"))
site
site<-as.matrix(sqlFetch(ch, "Enrollment.SiteInformation", rownames="SiteCode"))
site
str(site)
library(XML)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternet=TRUE)
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
fileUrl<- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
fileUrl<- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode
rootNode[[1]]
rootNode[[1]][[1]]
xmlSApply(rootNode,xmlValue)
xpathSApply(rootNode,"//zipcode",xmlValue)
xpathSApply(rootNode,"//zipcode==21231",xmlValue)
xpathSApply(rootNode,"@zipcode='21231',xmlValue)
)
xpathSApply(rootNode,"@zipcode='21231'",xmlValue)
xpathSApply(rootNode,"//zipcode='21231'",xmlValue)
library(swirl)
swirl()
mydf <- read.csv(path2csv, stringasFactors = FALSE)
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
print(tbl_df)
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(x:size))
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", count == "US")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version == "3.0.2", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500 )
filter(cran, size > 100500, r_os == "linux-gnu" )
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id)
)
arrange(cran2, package, ip_id)
arange(cran2, country, desc(r_version), ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb/2^10)
mutate(cran3, correct_size + 1000)
mutate(cran3, correct_size =  size + 1000)
summarize(cran, avg_bytes = mean(size))
swril()
swirl
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package(cran, package)
by_package<-(cran, package)
by_package<- group_by(cran, package)
by_package
summarize(by_package, mean(size))
source('C:/Users/MSQUIC~1/AppData/Local/Temp/Rtmp2jDcTK/summarize1.R')
source('C:/Users/MSQUIC~1/AppData/Local/Temp/Rtmp2jDcTK/summarize1.R')
source('C:/Users/MSQUIC~1/AppData/Local/Temp/Rtmp2jDcTK/summarize1.R')
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_count <- filter(pack_sum, count > 679)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, count)
top_counts_sorted <- arrange(top_counts, desc(count)
)
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
source('C:/Users/MSQUIC~1/AppData/Local/Temp/Rtmp2jDcTK/chain1.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
submit()
source('~/.active-rstudio-document', echo=TRUE)
submit()
submit()
source('C:/Users/MSQUIC~1/AppData/Local/Temp/Rtmp2jDcTK/chain2.R', echo=TRUE)
submit()
submit()
submit()
submit()
source('D:/Skitch/Code/R/DataScienceSpecialization/DataScienceSpecialization/GettingCleaningData/Course Project/run_analysis.R')
setwd("D:/Skitch/Code/R/DataScienceSpecialization/DataScienceSpecialization/GettingCleaningData/Course Project")
training.label.file <- "./UCI HAR Dataset/train/y_train.txt"
labels <- read.csv(training.label.file, header=FALSE)
head(labels)
activityLableFile <- "./UCI HAR Dataset/activity_labels.txt"
activityLables <- read.csv(activityLableFile, sep = " ", header=FALSE)
head(activityLables)
newLabels <- join(labels, activityLables, by='V1')
subjectFile <- "./UCI HAR Dataset/train/subject_train.txt"
subjects <- read.csv(subjectFile, header=FALSE)
head(subjects)
source('D:/Skitch/Code/R/DataScienceSpecialization/DataScienceSpecialization/GettingCleaningData/Course Project/run_analysis.R')
source('D:/Skitch/Code/R/DataScienceSpecialization/DataScienceSpecialization/GettingCleaningData/Course Project/run_analysis.R')
source('D:/Skitch/Code/R/DataScienceSpecialization/DataScienceSpecialization/GettingCleaningData/Course Project/run_analysis.R')
library(plyr)
library(data.table)
## Get the Activitity labes
## This will be common for both Training and Test data
activityLableFile <- "./UCI HAR Dataset/activity_labels.txt"
activityLables <- read.csv(activityLableFile, sep = " ", header=FALSE)
## Get the Training Date
training.label.file <- "./UCI HAR Dataset/train/y_train.txt"
trainingLabels <- read.csv(training.label.file, header=FALSE)
newTrainingLabels <- join(trainingLabels, activityLables, by='V1')
trainingSubjectFile <- "./UCI HAR Dataset/train/subject_train.txt"
trainingSubjects <- read.csv(trainingSubjectFile, header=FALSE)
# read the large data files by first reading 5 rows to get the column classes
trainingDataFile <- "./UCI HAR Dataset/train/X_train.txt"
first.5.rows <- read.table(trainingDataFile, header=FALSE, nrows = 5)
classes <- sapply(first.5.rows, class)
dt.Training.X <- read.table(trainingDataFile, header=FALSE, colClasses = classes)
# At this point should select only the columns that are needed?
# this wourld reduce the memory footprint and columns could be take
# right from documentation
# Add the subject and label information to the data table
dt.Training.X <- cbind(subjects, newTrainingLabels$V2, dt_X)
dt.Training.X <- cbind(trainingSubjects, newTrainingLabels$V2, dt_X)
newTrainingLabels <- join(trainingLabels, activityLables, by='V1')
dt.Training.X <- cbind(trainingSubjects, newTrainingLabels$V2, dt.Training.X)
## Get the Test Data
test.label.file <- "./UCI HAR Dataset/test/y_test.txt"
testLabels <- read.csv(test.label.file, header=FALSE)
newTestLabels <- join(testLabels, activityLables, by='V1')
testSubjectFile <- "./UCI HAR Dataset/train/subject_train.txt"
testSubjects <- read.csv(testSubjectFile, header=FALSE)
# read the large data files by first reading 5 rows to get the column classes
testDataFile <- "./UCI HAR Dataset/train/X_train.txt"
first.5.rows <- read.table(testDataFile, header=FALSE, nrows = 5)
classes <- sapply(first.5.rows, class)
dt.Test.X <- read.table(testDataFile, header=FALSE, colClasses = classes)
head(dt.Test.X[1:5],)
dt.Test.X <- cbind(testSubjects, newTestLabels$V2, dt.Test.X)
## Get the Activitity labes
## This will be common for both Training and Test data
activityLableFile <- "./UCI HAR Dataset/activity_labels.txt"
activityLables <- read.csv(activityLableFile, sep = " ", header=FALSE)
## Get the Test Data
test.label.file <- "./UCI HAR Dataset/test/y_test.txt"
testLabels <- read.csv(test.label.file, header=FALSE)
newTestLabels <- join(testLabels, activityLables, by='V1')
testSubjectFile <- "./UCI HAR Dataset/test/subject_test.txt"
testSubjects <- read.csv(testSubjectFile, header=FALSE)
# read the large data files by first reading 5 rows to get the column classes
testDataFile <- "./UCI HAR Dataset/test/X_test.txt"
first.5.rows <- read.table(testDataFile, header=FALSE, nrows = 5)
classes <- sapply(first.5.rows, class)
dt.Test.X <- read.table(testDataFile, header=FALSE, colClasses = classes)
# Add the subject and label information to the data table
dt.Test.X <- cbind(testSubjects, newTestLabels$V2, dt.Test.X)
head(dt.Test.X[1:5],)
keep <- c(1:6, 41:46, 81:86, 121:126, 201:202, 214:215, 227:228, 240:241,
294:296, 345:350, 373:375, 424:429, 452:454, 503:504, 516:517,
529:530, 539, 542:543, 552, 553:561)
dim(keep)
keep
length(keep)
keep <- c(1:6, 41:46, 81:86, 121:126, 161:166, 201:202, 214:215, 227:228, 240:241,
253:254, 266:271, 294:296, 345:350, 373:375, 424:429, 452:454,
503:504, 516:517, 529:530, 539, 542:543, 552, 555:561)
keep <- c(1:6, 41:46, 81:86, 121:126, 161:166, 201:202, 214:215, 227:228, 240:241,
253:254, 266:271, 294:296, 345:350, 373:375, 424:429, 452:454,
503:504, 513, 516:517, 526, 529:530, 539, 542:543, 552, 555:561)
length(keep)
head(dt.Test.X[1:10],)
head(subset(dt.Test.X, keep)[1:10])
head(subset(dt.Test.X, , keep)[1:10])
dt.Test.X <- subset(dt.Test.X, , keep)
source('D:/Skitch/Code/R/DataScienceSpecialization/DataScienceSpecialization/GettingCleaningData/Course Project/run_analysis.R')
run_analysis
run_analysis()
## Get the Activitity labes
## This will be common for both Training and Test data
activityLableFile <- "./UCI HAR Dataset/activity_labels.txt"
activityLables <- read.csv(activityLableFile, sep = " ", header=FALSE)
# Get the mean() and std() columns to keep
keep <- c(1:6, 41:46, 81:86, 121:126, 161:166, 201:202, 214:215, 227:228, 240:241,
253:254, 266:271, 294:296, 345:350, 373:375, 424:429, 452:454,
503:504, 513, 516:517, 526, 529:530, 539, 542:543, 552, 555:561)
## Get the Training Date
training.label.file <- "./UCI HAR Dataset/train/y_train.txt"
trainingLabels <- read.csv(training.label.file, header=FALSE)
newTrainingLabels <- join(trainingLabels, activityLables, by='V1')
trainingSubjectFile <- "./UCI HAR Dataset/train/subject_train.txt"
trainingSubjects <- read.csv(trainingSubjectFile, header=FALSE)
# read the large data files by first reading 5 rows to get the column classes
trainingDataFile <- "./UCI HAR Dataset/train/X_train.txt"
first.5.rows <- read.table(trainingDataFile, header=FALSE, nrows = 5)
classes <- sapply(first.5.rows, class)
dt.Training.X <- read.table(trainingDataFile, header=FALSE, colClasses = classes)
## Keep on the columns of interest
dt.Training.X <- subset(dt.Training.X, , keep)
# Add the subject and label information to the data table
dt.Training.X <- cbind(trainingSubjects, newTrainingLabels$V2, dt.Training.X)
## Get the Test Data
test.label.file <- "./UCI HAR Dataset/test/y_test.txt"
testLabels <- read.csv(test.label.file, header=FALSE)
newTestLabels <- join(testLabels, activityLables, by='V1')
testSubjectFile <- "./UCI HAR Dataset/test/subject_test.txt"
testSubjects <- read.csv(testSubjectFile, header=FALSE)
# read the large data files by first reading 5 rows to get the column classes
testDataFile <- "./UCI HAR Dataset/test/X_test.txt"
first.5.rows <- read.table(testDataFile, header=FALSE, nrows = 5)
classes <- sapply(first.5.rows, class)
dt.Test.X <- read.table(testDataFile, header=FALSE, colClasses = classes)
## Keep on the columns of interest
dt.Test.X <- subset(dt.Test.X, , keep)
# Add the subject and label information to the data table
dt.Test.X <- cbind(testSubjects, newTestLabels$V2, dt.Test.X)
head(dt.Test.X[1:10],)
dt.Test.X <- subset(dt.Test.X, , keep)
dt.X <- rbind(dt.Training.X, dt.Test.X)
head(dt.Training.X[1:10],)
rm(dt.Test.X, dt.Training.X)
rm(dt.Test.X, newTestLabels,  testLabels, testSubjects)
rm(dt.Training.X, newTrainingLabels, trainingLabels, trainingSubjects)
rm(activityLables, first.5.rows)
source('D:/Skitch/Code/R/DataScienceSpecialization/DataScienceSpecialization/GettingCleaningData/Course Project/run_analysis.R')
source('D:/Skitch/Code/R/DataScienceSpecialization/DataScienceSpecialization/GettingCleaningData/Course Project/run_analysis.R')
run_analysis()
## Get the Activitity labes
## This will be common for both Training and Test data
activityLableFile <- "./UCI HAR Dataset/activity_labels.txt"
activityLables <- read.csv(activityLableFile, sep = " ", header=FALSE)
# Get the mean() and std() columns to keep
keep <- c(1:6, 41:46, 81:86, 121:126, 161:166, 201:202, 214:215, 227:228, 240:241,
253:254, 266:271, 294:296, 345:350, 373:375, 424:429, 452:454,
503:504, 513, 516:517, 526, 529:530, 539, 542:543, 552, 555:561)
column.Names <- c("SubjectID", "Activity")
## Get the Training Date
training.label.file <- "./UCI HAR Dataset/train/y_train.txt"
trainingLabels <- read.csv(training.label.file, header=FALSE)
newTrainingLabels <- join(trainingLabels, activityLables, by='V1')
trainingSubjectFile <- "./UCI HAR Dataset/train/subject_train.txt"
trainingSubjects <- read.csv(trainingSubjectFile, header=FALSE)
# read the large data files by first reading 5 rows to get the column classes
trainingDataFile <- "./UCI HAR Dataset/train/X_train.txt"
first.5.rows <- read.table(trainingDataFile, header=FALSE, nrows = 5)
classes <- sapply(first.5.rows, class)
dt.Training.X <- read.table(trainingDataFile, header=FALSE, colClasses = classes)
## Keep on the columns of interest
dt.Training.X <- subset(dt.Training.X, , keep)
# Add the subject and label information to the data table
dt.Training.X <- cbind(trainingSubjects, newTrainingLabels$V2, dt.Training.X)
# Rename the columns
names(dt.Training.X) <- column.Names
head(dt.Training.X)
## Get the Test Data
test.label.file <- "./UCI HAR Dataset/test/y_test.txt"
testLabels <- read.csv(test.label.file, header=FALSE)
newTestLabels <- join(testLabels, activityLables, by='V1')
testSubjectFile <- "./UCI HAR Dataset/test/subject_test.txt"
testSubjects <- read.csv(testSubjectFile, header=FALSE)
# read the large data files by first reading 5 rows to get the column classes
testDataFile <- "./UCI HAR Dataset/test/X_test.txt"
first.5.rows <- read.table(testDataFile, header=FALSE, nrows = 5)
classes <- sapply(first.5.rows, class)
dt.Test.X <- read.table(testDataFile, header=FALSE, colClasses = classes)
## Keep on the columns of interest
dt.Test.X <- subset(dt.Test.X, , keep)
# Add the subject and label information to the data table
dt.Test.X <- cbind(testSubjects, newTestLabels$V2, dt.Test.X)
# Rename the columns
names(dt.Test.X) <- column.Names
head(dt.Test.X[1:10],)
head(dt.Training.X[1:10],)
rm(activityLables, first.5.rows)
rm(dt.Test.X, newTestLabels,  testLabels, testSubjects)
rm(dt.Training.X, newTrainingLabels, trainingLabels, trainingSubjects)
dt.Test.X <- subset(dt.Test.X, , keep)
source('D:/Skitch/Code/R/DataScienceSpecialization/DataScienceSpecialization/GettingCleaningData/Course Project/run_analysis.R')
run_analysis()
head(run_analysis()[1:10])
dt <- run_analysis()
source('D:/Skitch/Code/R/DataScienceSpecialization/DataScienceSpecialization/GettingCleaningData/Course Project/run_analysis.R')
dt <- run_analysis()
